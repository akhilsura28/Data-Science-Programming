{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4a5cb5-cf11-40c4-b5b6-8995b699f0ba",
   "metadata": {},
   "source": [
    "* Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3c4dd0-dad9-47c4-aa43-5203d7942966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(86089106)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6d4b8-4191-410f-900f-d5c0bbf8e137",
   "metadata": {},
   "source": [
    "* Load the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f1e44a-9cec-4f0e-94f5-6952243c20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('universal-bank-X-train-data.csv') \n",
    "y_train = pd.read_csv('universal-bank-y-train-data.csv') \n",
    "X_test = pd.read_csv('universal-bank-X-test-data.csv') \n",
    "y_test = pd.read_csv('universal-bank-y-test-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6952cd-c37f-4b27-a750-4c442f053d0e",
   "metadata": {},
   "source": [
    "### Model the data\n",
    "\n",
    "First, we will create a dataframe to hold all the results of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefbd557-7856-4e6a-932a-d39cbc1bf830",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ac268-f4a1-4328-bcd1-6096262d9963",
   "metadata": {},
   "source": [
    "### Fitting a DTree classification model using Grid Search (paramater tuning set 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e229ad-6100-47b4-8889-02827b6176ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5000 candidates, totalling 25000 fits\n",
      "The best recall score is 0.7231450719822813\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 30, 'max_leaf_nodes': 100, 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [2,10,50,100,200],  \n",
    "    'min_samples_leaf': [1,5,10,20,50],\n",
    "    'min_impurity_decrease': [0.0001, 0.0005, 0.0010, 0.0020, 0.0050],\n",
    "    'max_leaf_nodes': [10,25,50,100,200], \n",
    "    'max_depth': [5,10,20,30], \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2544d380-e709-48e6-8060-ac2362735b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9653 Precision=0.7079 Recall=0.7079 F1=0.7079\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree GridSearch</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  Accuracy  Precision    Recall        F1\n",
       "0  DTree GridSearch  0.965333   0.707865  0.707865  0.707865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.4f} Precision={TP/(TP+FP):.4f} Recall={TP/(TP+FN):.4f} F1={2*TP/(2*TP+FP+FN):.4f}\")\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"DTree GridSearch\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bdf56-277d-4547-95cc-1c322b636563",
   "metadata": {},
   "source": [
    "### Fitting a DTree classification model using Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7ccdb8-482a-44f4-95eb-5e107391fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "The best recall score is 0.6854928017718714\n",
      "... with parameters: {'min_samples_split': 166, 'min_samples_leaf': 10, 'min_impurity_decrease': 0.00030000000000000003, 'max_leaf_nodes': 153, 'max_depth': 12, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(4,200),  \n",
    "    'min_samples_leaf': np.arange(4,200),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(10, 200), \n",
    "    'max_depth': np.arange(3,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=1000,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5527c206-12e0-4237-bdff-0b902de2b222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9633333 Precision=0.6888889 Recall=0.6966292 F1=0.6927374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree GridSearch</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree RandomSearch</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    DTree GridSearch  0.965333   0.707865  0.707865  0.707865\n",
       "0  DTree RandomSearch  0.963333   0.688889  0.696629  0.692737"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, rand_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"DTree RandomSearch\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66319b6b-ab4c-4014-9108-a037bcf9b907",
   "metadata": {},
   "source": [
    "### Conducting an exhaustive search across a smaller range of parameters around the parameters found in the above random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b65fbaf-e134-42f1-827e-d8299edff76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "The best recall score is 0.6854928017718714\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 151, 'min_impurity_decrease': 0.00020000000000000004, 'min_samples_leaf': 8, 'min_samples_split': 164}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68263d7b-29ad-4597-a63c-1cfafa4bd21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9633 Precision=0.6889 Recall=0.6966 F1=0.6927\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree GridSearch</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree RandomSearch</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree exhaustive Grid Search</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  Accuracy  Precision    Recall        F1\n",
       "0              DTree GridSearch  0.965333   0.707865  0.707865  0.707865\n",
       "0            DTree RandomSearch  0.963333   0.688889  0.696629  0.692737\n",
       "0  DTree exhaustive Grid Search  0.963333   0.688889  0.696629  0.692737"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.4f} Precision={TP/(TP+FP):.4f} Recall={TP/(TP+FN):.4f} F1={2*TP/(2*TP+FP+FN):.4f}\")\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"DTree exhaustive Grid Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20095027-340a-43c6-9d4c-84f6b0707995",
   "metadata": {},
   "source": [
    "## Fitting and testing with Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23d4ad7-874b-4a4c-93d8-591e07ca9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(penalty=None, max_iter=900)\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9b03d3-93e8-48d9-933b-1f18383ad9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree GridSearch</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree RandomSearch</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree exhaustive Grid Search</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  Accuracy  Precision    Recall        F1\n",
       "0              DTree GridSearch  0.965333   0.707865  0.707865  0.707865\n",
       "0            DTree RandomSearch  0.963333   0.688889  0.696629  0.692737\n",
       "0  DTree exhaustive Grid Search  0.963333   0.688889  0.696629  0.692737\n",
       "0              default logistic  0.978667   1.000000  0.640449  0.780822"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81839599-a68a-4c2c-b317-662459bc9efa",
   "metadata": {},
   "source": [
    "## Fitting and testing with Logistic Regression L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b73fb0-336b-4307-a2b7-a86c463ffee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L2_model = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "_ = log_reg_L2_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d433ad3c-9334-4873-8f5d-4d0b09d0f72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree GridSearch</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree RandomSearch</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree exhaustive Grid Search</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  Accuracy  Precision    Recall        F1\n",
       "0              DTree GridSearch  0.965333   0.707865  0.707865  0.707865\n",
       "0            DTree RandomSearch  0.963333   0.688889  0.696629  0.692737\n",
       "0  DTree exhaustive Grid Search  0.963333   0.688889  0.696629  0.692737\n",
       "0              default logistic  0.978667   1.000000  0.640449  0.780822\n",
       "0                   L2 logistic  0.978667   1.000000  0.640449  0.780822"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_L2_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L2 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b97b833-d573-4888-8d49-88a7c874306d",
   "metadata": {},
   "source": [
    "## Fitting and testing with Logistic Regression L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f7c6e17-30f7-49b8-bb70-1620ac4252af",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L1_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "_ = log_reg_L1_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e94f03f2-2bb5-4ea3-ba2e-899a26b236d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree GridSearch</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree RandomSearch</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree exhaustive Grid Search</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  Accuracy  Precision    Recall        F1\n",
       "0              DTree GridSearch  0.965333   0.707865  0.707865  0.707865\n",
       "0            DTree RandomSearch  0.963333   0.688889  0.696629  0.692737\n",
       "0  DTree exhaustive Grid Search  0.963333   0.688889  0.696629  0.692737\n",
       "0              default logistic  0.978667   1.000000  0.640449  0.780822\n",
       "0                   L2 logistic  0.978667   1.000000  0.640449  0.780822\n",
       "0                   L1 logistic  0.978667   1.000000  0.640449  0.780822"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_L1_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L1 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b82e1-105c-4a81-9371-e5081e1eca0f",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70fae39f-97bc-4d52-96f9-6d4421237886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree RandomSearch</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree exhaustive Grid Search</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.692737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree GridSearch</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  Accuracy  Precision    Recall        F1\n",
       "0              default logistic  0.978667   1.000000  0.640449  0.780822\n",
       "0                   L2 logistic  0.978667   1.000000  0.640449  0.780822\n",
       "0                   L1 logistic  0.978667   1.000000  0.640449  0.780822\n",
       "0            DTree RandomSearch  0.963333   0.688889  0.696629  0.692737\n",
       "0  DTree exhaustive Grid Search  0.963333   0.688889  0.696629  0.692737\n",
       "0              DTree GridSearch  0.965333   0.707865  0.707865  0.707865"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60457cc4-2346-4ab9-87a9-df1b41f2fa5b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, I have tried to identify the best predictive model using the relavant models for the case situation. Here, in order to determine the best model for predicting potential new Certificate of Deposit (CD) account customers for Universal Bank, we need to choose an evaluation metric that aligns with the requirements of the bank. In the decision tree models, I have optimized the models for Recall score in the event that the goal of the bank is to identify as many CD account customers as possible, even it means including some false positives. \n",
    "\n",
    "From the resulting performance metrics - accuracy, precision, recall, and F1 scoreâ€”we can consider the following:\n",
    "\n",
    "Accuracy: This metric measures the overall correctness of the model's predictions, indicating the proportion of correctly classified instances. However, accuracy alone might not be the best choice if there are imbalances in dataset, where one class (e.g., potential CD account customers) significantly outnumbers the other class (e.g., non-customers).\n",
    "\n",
    "Precision: Precision represents the proportion of correctly predicted positive instances (potential CD account customers) out of all instances predicted as positive. It focuses on minimizing false positives, which could be important if the bank wants to avoid targeting individuals who are not likely to become CD account customers.\n",
    "\n",
    "Recall: Recall(sensitivity) measures the proportion of correctly predicted positive instances out of all actual positive instances. It is particularly relevant when the goal is to identify as many potential CD account customers as possible, even if it means including some false positives.\n",
    "\n",
    "F1 Score: The F1 score is the harmonic mean of precision and recall. It provides a balance between precision and recall and is useful when both false positives and false negatives are equally important. It is a good choice when there is a trade-off between precision and recall, and the bank wants to consider both aspects simultaneously.\n",
    "\n",
    "Based on the resulting evaluation metrics, we can see that all the variations of logistic models perform equally well in all the metrics and have the best accuracy(0.978667), precision(1.0) and F1 score(0.780822). The decision tree models perform best in terms of Recall score with DTree Grid search having the best Recall score of 0.707865. \n",
    "\n",
    "Finally, the best evaluation metric to choose depends on the priorities of Universal Bank. If Universal Bank wants to prioritize correctly identifying potential customers, recall would be the most important metric to consider. But, if minimizing false positives (ensuring the customers identified are truly potential customers) is the priority, precision should be emphasized. If both precision and recall are equally important, the F1 score can provide a balanced assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a82c9-7213-4e03-8569-00f1b6f6a549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
