{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d17b081-ffa8-4a47-9e15-69acc35f03e6",
   "metadata": {},
   "source": [
    "Create a new notebook. Use the data from airbnb with a target of price_gte_150 to fit a Decision tree model using the randomsearch/gridsearch approach demonstrated in the tutorial. Use precision as the scoring measure to optimize.\n",
    "\n",
    "Create a discussion section at the end of your notebook. In this section, present and discuss your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8075040-c41a-4fd7-b2bc-f150bb91af1c",
   "metadata": {},
   "source": [
    "* Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234d861b-ed84-4bb6-b24c-35d47f17e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "np.random.seed(86089106)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed83353-d39d-4097-968f-289e40d59df8",
   "metadata": {},
   "source": [
    "* Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3fa71b4-7e8f-4fb4-ac0a-36205ecca394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('airbnb_train_X_price_gte_150.csv') \n",
    "y_train = pd.read_csv('airbnb_train_y_price_gte_150.csv') \n",
    "X_test = pd.read_csv('airbnb_test_X_price_gte_150.csv') \n",
    "y_test = pd.read_csv('airbnb_test_y_price_gte_150.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5a8a2-f074-4b58-a5ae-d142359a8926",
   "metadata": {},
   "source": [
    "* Conducting an initial random search across a wide range of possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4a74944-6bbb-402e-8413-1b007c64353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "The best precision score is 0.8511730370184265\n",
      "... with parameters: {'min_samples_split': 127, 'min_samples_leaf': 16, 'min_impurity_decrease': 0.0008000000000000001, 'max_leaf_nodes': 166, 'max_depth': 27, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(4,200),  \n",
    "    'min_samples_leaf': np.arange(2,200),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(10, 200), \n",
    "    'max_depth': np.arange(3,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=1000,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dacf6bf7-ae27-41cd-b3d4-b9900ff33b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.8378632 Precision=0.8185053 Recall=0.8662900 F1=0.8417200\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, rand_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ab29e-84ae-4ea2-b5bd-1a2ac771e240",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "* In the above cells, I have trained the model using 5 fold cross validation with precision to optimize the model. This indicates that data set was divided into 5 equal folds and model was trained and evaluated 5 times, each time using a different fold as test set and the remaining folds as training set. This process is repeated for a total of 1000 different candidate models, resulting in 5000 fits.\n",
    "\n",
    "* The best precision score achieved by one of the candidate models is 0.8511730370184265. Here, precision indicates the accuracy of positive predictions made by the model. A higher precision score means that a model has lower rate of false positive predictions.\n",
    "\n",
    "* Overall, among the 1000 candidate models, the one with the parameters indicated in the output achieved the best precision score.\n",
    "\n",
    "* From the confusion matrix of the test data, we can analyse the performance of the model. Here, the model predicts the price of a room on airbnb. \n",
    "\n",
    "    * The model achieved an accuracy of 0.8378632, which measures the overall correctness of the predictions. \n",
    "    * Precision indicates the accuracy of positive predictions, indicating how well the model avoids false positive predictions. The precision score of 0.8185053 indicates that the model has a high proportion of true positive predictions relative to the total number of positive predictions.\n",
    "    * Recall indicates the model's ability to find all the relevant positive instances. The recall score of 0.8662900 represents the proportion of true positive predictions the model was able to identify out of all actual positive instances in the dataset. \n",
    "    * F1 score combines both precision and recall into a single metric, where higher value indicates better overall performance. The F1 score of 0.8417200 is the harmonic mean of precision and recall, providing an overall assessment of the model's performance.\n",
    "    * From the results, I can say the model achieved reasonably good results on the test data for predicting the price of a room on Airbnb.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a14c35-44d6-42db-8411-ddaf02d05446",
   "metadata": {},
   "source": [
    "### Further Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee92c6-df89-424a-b707-068aa26fd5ff",
   "metadata": {},
   "source": [
    "*  We can also conduct a further exhaustive search across a smaller range of parameters around the parameters found in the initial random search for further optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "622be099-589d-4485-99ff-0137d1170732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1280 candidates, totalling 6400 fits\n",
      "The best precision score is 0.8511730370184265\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 25, 'max_leaf_nodes': 164, 'min_impurity_decrease': 0.0007000000000000001, 'min_samples_leaf': 15, 'min_samples_split': 125}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "832d12c0-9215-4f84-bde9-81f96bbc1984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.8379 Precision=0.8185 Recall=0.8663 F1=0.8417\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.4f} Precision={TP/(TP+FP):.4f} Recall={TP/(TP+FN):.4f} F1={2*TP/(2*TP+FP+FN):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75729c25-1ab8-4471-b826-c361f83f7b8d",
   "metadata": {},
   "source": [
    "* Importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2329cd70-3cdd-4ded-8e8c-0d51dd3db438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.06, 0.1 , 0.64, 0.01, 0.01, 0.06, 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.02, 0.01, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.03, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(grid_search.best_estimator_.feature_importances_,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb071d2e-6734-4c2d-8aff-2ee34b950b5d",
   "metadata": {},
   "source": [
    "### Summary of Further Exploration\n",
    "\n",
    "* Above, we have done grid search using cross validation to further optimize the decision tree model again with precision as scoring measure.\n",
    "\n",
    "* Here we have used Grid search with 5-fold cross validation. The grid search iterates over all possible combinations of hyperparameters within the specified ranges and evaluates each model's performance using precision as the scoring metric. The best precision score and the corresponding best parameters are printed in the output.\n",
    "\n",
    "* Comparision of performance with respect to the confusion matrix results -\n",
    "\n",
    "    * By observation, I can say that results obtained after the grid search did not result in any improvement or deterioration in the performance metrics compared to the previous results. The precision, recall, accuracy, and F1 score remain the same. It suggests that the model's performance did not significantly change after fine-tuning the hyperparameters using the grid search.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
