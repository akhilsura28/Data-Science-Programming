{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxGJbLsUhuc8"
   },
   "source": [
    "# WE03b-Ensembles - Modelling\n",
    "\n",
    "In this notebook, I will be implementing the following ensemble models to find the best fit for predicting the Car Acceptability.\n",
    "\n",
    "* Decision Tree with RandomSearchCV\n",
    "* Decision Tree with GridSearchCV\n",
    "* Random Forest (Default)\n",
    "* Random Forest with RandomSearch\n",
    "* Random Forest with GridSearch\n",
    "* AdaBoost (Default)\n",
    "* Gradiant Boosting (Default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmYLcm3aY8X5"
   },
   "source": [
    "## Install and import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install xgboost (it's not part of the sklearn package)\n",
    "# !conda install xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8zNdljvIhuc8"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "np.random.seed(86089106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGgrXNQPZT3J"
   },
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q3u5LsGyhudA"
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('car-X-train_data.csv') \n",
    "y_train = pd.read_csv('car-y-train_data.csv') \n",
    "X_test = pd.read_csv('car-X-test_data.csv') \n",
    "y_test = pd.read_csv('car-y-test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataframe to store the results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2A_u7rQhuc_"
   },
   "source": [
    "## Prediction with Decision Tree (using default parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UZ60Vn1AhudK"
   },
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntgxBhvJXkjp"
   },
   "source": [
    "Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "xPL4rRlVhudM",
    "outputId": "db26a1f0-23c9-4a02-87c5-34e3dbd71ccf"
   },
   "outputs": [],
   "source": [
    "_ = dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMvD4-9wXy_1"
   },
   "source": [
    "Review of the performance of the model on the validation/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "YAcO31dIX7JE",
    "outputId": "797a7c84-5c1c-4ec8-c75e-12c675ea8061"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree Default</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.932645</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  Accuracy  Precision    Recall        F1\n",
       "0  Dtree Default  0.971098   0.932645  0.966359  0.948756"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Dtree Default\",       \n",
    "                                                    'Accuracy': accuracy_score(y_test, y_pred), \n",
    "                                                    'Precision': precision_score(y_test, y_pred, average = 'macro'), \n",
    "                                                    'Recall': recall_score(y_test, y_pred, average = 'macro'), \n",
    "                                                    'F1': f1_score(y_test, y_pred, average = 'macro')\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING DECISION TREE WITH RANDOM SEARCH CV TO TRAIN AND TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "The best accuracy score is 0.9536847158876581\n",
      "... with parameters: {'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0004, 'max_leaf_nodes': 123, 'max_depth': 44, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,200),  \n",
    "    'min_samples_leaf': np.arange(1,200),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(10, 200), \n",
    "    'max_depth': np.arange(3,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=1000,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree Default</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.932645</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with RandomSearch</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  Accuracy  Precision    Recall        F1\n",
       "0            Dtree Default  0.971098   0.932645  0.966359  0.948756\n",
       "0  Dtree with RandomSearch  0.944882   0.739130  0.944444  0.829268"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, rand_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Dtree with RandomSearch\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING DECISION TREE WITH GRID SEARCH CV TO TRAIN AND TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5000 candidates, totalling 25000 fits\n",
      "The best accuracy score is 0.9669112856212063\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 20, 'max_leaf_nodes': 50, 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [2,10,50,100,200],  \n",
    "    'min_samples_leaf': [1,5,10,20,50],\n",
    "    'min_impurity_decrease': [0.0001, 0.0005, 0.0010, 0.0020, 0.0050],\n",
    "    'max_leaf_nodes': [10,25,50,100,200], \n",
    "    'max_depth': [5,10,20,30], \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree Default</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.932645</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with RandomSearch</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with GridSearch</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  Accuracy  Precision    Recall        F1\n",
       "0            Dtree Default  0.971098   0.932645  0.966359  0.948756\n",
       "0  Dtree with RandomSearch  0.944882   0.739130  0.944444  0.829268\n",
       "0    Dtree with GridSearch  0.945312   0.772727  0.894737  0.829268"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "#print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.4f} Precision={TP/(TP+FP):.4f} Recall={TP/(TP+FN):.4f} F1={2*TP/(2*TP+FP+FN):.4f}\")\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Dtree with GridSearch\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with RandomForest (using default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = rforest.fit(X_train, y_train)\n",
    "_ = rforest.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree Default</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.932645</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with RandomSearch</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with GridSearch</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest Default</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>0.879193</td>\n",
       "      <td>0.874113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  Accuracy  Precision    Recall        F1\n",
       "0            Dtree Default  0.971098   0.932645  0.966359  0.948756\n",
       "0  Dtree with RandomSearch  0.944882   0.739130  0.944444  0.829268\n",
       "0    Dtree with GridSearch  0.945312   0.772727  0.894737  0.829268\n",
       "0     RandomForest Default  0.953757   0.869281  0.879193  0.874113"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"RandomForest Default\",       \n",
    "                                                    'Accuracy': accuracy_score(y_test, y_pred), \n",
    "                                                    'Precision': precision_score(y_test, y_pred, average = 'macro'), \n",
    "                                                    'Recall': recall_score(y_test, y_pred, average = 'macro'), \n",
    "                                                    'F1': f1_score(y_test, y_pred, average = 'macro')\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING RANDOM FOREST CLASSIFIER WITH RANDOM SEARCH CV TO TRAIN AND TEST THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "The best accuracy score is 0.9462295531703303\n",
      "... with parameters: {'min_samples_split': 6, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0009000000000000002, 'max_leaf_nodes': 79, 'max_depth': 44, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,200),  \n",
    "    'min_samples_leaf': np.arange(1,200),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(10, 200), \n",
    "    'max_depth': np.arange(3,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "rforest = RandomForestClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = rforest, param_distributions=param_grid, cv=kfolds, n_iter=1000,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, rand_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "#print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest with Random search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING RANDOM FOREST CLASSIFIER WITH GRID SEARCH CV TO TRAIN AND TEST THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5000 candidates, totalling 25000 fits\n",
      "The best accuracy score is 0.9578169472926168\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 30, 'max_leaf_nodes': 100, 'min_impurity_decrease': 0.0005, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [2,10,50,100,200],  \n",
    "    'min_samples_leaf': [1,5,10,20,50],\n",
    "    'min_impurity_decrease': [0.0001, 0.0005, 0.0010, 0.0020, 0.0050],\n",
    "    'max_leaf_nodes': [10,25,50,100,200], \n",
    "    'max_depth': [5,10,20,30], \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "rforest = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = rforest, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree Default</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.932645</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with RandomSearch</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with GridSearch</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest Default</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>0.879193</td>\n",
       "      <td>0.874113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with Random search</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with Grid search</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  Accuracy  Precision    Recall        F1\n",
       "0                     Dtree Default  0.971098   0.932645  0.966359  0.948756\n",
       "0           Dtree with RandomSearch  0.944882   0.739130  0.944444  0.829268\n",
       "0             Dtree with GridSearch  0.945312   0.772727  0.894737  0.829268\n",
       "0              RandomForest Default  0.953757   0.869281  0.879193  0.874113\n",
       "0  Random Forest with Random search  0.941176   0.785714  0.733333  0.758621\n",
       "0    Random Forest with Grid search  0.941176   0.785714  0.733333  0.758621"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, rand_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "#print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest with Grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with ADABoost (using default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = aboost.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = aboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilsura/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree Default</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.932645</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with RandomSearch</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with GridSearch</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest Default</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>0.879193</td>\n",
       "      <td>0.874113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with Random search</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with Grid search</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost Default</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.488789</td>\n",
       "      <td>0.604545</td>\n",
       "      <td>0.521558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  Accuracy  Precision    Recall        F1\n",
       "0                     Dtree Default  0.971098   0.932645  0.966359  0.948756\n",
       "0           Dtree with RandomSearch  0.944882   0.739130  0.944444  0.829268\n",
       "0             Dtree with GridSearch  0.945312   0.772727  0.894737  0.829268\n",
       "0              RandomForest Default  0.953757   0.869281  0.879193  0.874113\n",
       "0  Random Forest with Random search  0.941176   0.785714  0.733333  0.758621\n",
       "0    Random Forest with Grid search  0.941176   0.785714  0.733333  0.758621\n",
       "0                  AdaBoost Default  0.809249   0.488789  0.604545  0.521558"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"AdaBoost Default\",       \n",
    "                                                    'Accuracy': accuracy_score(y_test, y_pred), \n",
    "                                                    'Precision': precision_score(y_test, y_pred, average = 'macro'), \n",
    "                                                    'Recall': recall_score(y_test, y_pred, average = 'macro'), \n",
    "                                                    'F1': f1_score(y_test, y_pred, average = 'macro')\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = gboost.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree Default</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.932645</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with RandomSearch</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with GridSearch</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest Default</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>0.879193</td>\n",
       "      <td>0.874113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with Random search</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with Grid search</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost Default</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.488789</td>\n",
       "      <td>0.604545</td>\n",
       "      <td>0.521558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoost Default</td>\n",
       "      <td>0.965318</td>\n",
       "      <td>0.899981</td>\n",
       "      <td>0.958024</td>\n",
       "      <td>0.924825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  Accuracy  Precision    Recall        F1\n",
       "0                     Dtree Default  0.971098   0.932645  0.966359  0.948756\n",
       "0           Dtree with RandomSearch  0.944882   0.739130  0.944444  0.829268\n",
       "0             Dtree with GridSearch  0.945312   0.772727  0.894737  0.829268\n",
       "0              RandomForest Default  0.953757   0.869281  0.879193  0.874113\n",
       "0  Random Forest with Random search  0.941176   0.785714  0.733333  0.758621\n",
       "0    Random Forest with Grid search  0.941176   0.785714  0.733333  0.758621\n",
       "0                  AdaBoost Default  0.809249   0.488789  0.604545  0.521558\n",
       "0             GradientBoost Default  0.965318   0.899981  0.958024  0.924825"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"GradientBoost Default\",       \n",
    "                                                    'Accuracy': accuracy_score(y_test, y_pred), \n",
    "                                                    'Precision': precision_score(y_test, y_pred, average = 'macro'), \n",
    "                                                    'Recall': recall_score(y_test, y_pred, average = 'macro'), \n",
    "                                                    'F1': f1_score(y_test, y_pred, average = 'macro')\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost Default</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.488789</td>\n",
       "      <td>0.604545</td>\n",
       "      <td>0.521558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with Random search</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with Grid search</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with RandomSearch</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree with GridSearch</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest Default</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>0.879193</td>\n",
       "      <td>0.874113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoost Default</td>\n",
       "      <td>0.965318</td>\n",
       "      <td>0.899981</td>\n",
       "      <td>0.958024</td>\n",
       "      <td>0.924825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree Default</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.932645</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  Accuracy  Precision    Recall        F1\n",
       "0                  AdaBoost Default  0.809249   0.488789  0.604545  0.521558\n",
       "0  Random Forest with Random search  0.941176   0.785714  0.733333  0.758621\n",
       "0    Random Forest with Grid search  0.941176   0.785714  0.733333  0.758621\n",
       "0           Dtree with RandomSearch  0.944882   0.739130  0.944444  0.829268\n",
       "0             Dtree with GridSearch  0.945312   0.772727  0.894737  0.829268\n",
       "0              RandomForest Default  0.953757   0.869281  0.879193  0.874113\n",
       "0             GradientBoost Default  0.965318   0.899981  0.958024  0.924825\n",
       "0                     Dtree Default  0.971098   0.932645  0.966359  0.948756"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on the above results of ensemble models for used car acceptability, we can analyse the results as follows:\n",
    "\n",
    "1. AdaBoost Default:\n",
    "   - Accuracy: 0.809249\n",
    "   - Precision: 0.488789\n",
    "   - Recall: 0.604545\n",
    "   - F1 Score: 0.521558\n",
    "   * From the scores, I can say, this model seems to have moderate accuracy and performance metrics compared to the other models.\n",
    "\n",
    "2. Random Forest with Random Search:\n",
    "   - Accuracy: 0.941176\n",
    "   - Precision: 0.785714\n",
    "   - Recall: 0.733333\n",
    "   - F1 Score: 0.758621\n",
    "   \n",
    "   * Random Forest with Random Search shows improved performance across all metrics compared to the AdaBoost model.\n",
    "\n",
    "3. Random Forest with Grid Search:\n",
    "   - Accuracy: 0.941176\n",
    "   - Precision: 0.785714\n",
    "   - Recall: 0.733333\n",
    "   - F1 Score: 0.758621\n",
    "   \n",
    "   * The Random Forest model with Grid Search achieves the same performance as the Random Forest with Random Search.\n",
    "\n",
    "4. Decision Tree with Random Search:\n",
    "   - Accuracy: 0.944882\n",
    "   - Precision: 0.739130\n",
    "   - Recall: 0.944444\n",
    "   - F1 Score: 0.829268\n",
    "   * The Decision Tree model with Random Search demonstrates higher recall but lower precision compared to the Random Forest models.\n",
    "\n",
    "5. Decision Tree with Grid Search:\n",
    "   - Accuracy: 0.945312\n",
    "   - Precision: 0.772727\n",
    "   - Recall: 0.894737\n",
    "   - F1 Score: 0.829268\n",
    "   \n",
    "   * Similar to the Decision Tree with Random Search, this model has high recall but slightly improved precision.\n",
    "\n",
    "6. RandomForest Default:\n",
    "   - Accuracy: 0.953757\n",
    "   - Precision: 0.869281\n",
    "   - Recall: 0.879193\n",
    "   - F1 Score: 0.874113\n",
    "   \n",
    "   * The default Random Forest model has high accuracy and performance across all metrics.\n",
    "\n",
    "7. Gradient Boost Default:\n",
    "   - Accuracy: 0.965318\n",
    "   - Precision: 0.899981\n",
    "   - Recall: 0.958024\n",
    "   - F1 Score: 0.924825\n",
    "   \n",
    "   * The Gradient Boosting model achieves even higher accuracy and performance metrics, making it one of the top-performing models.\n",
    "\n",
    "8. Decision Tree Default:\n",
    "   - Accuracy: 0.971098\n",
    "   - Precision: 0.932645\n",
    "   - Recall: 0.966359\n",
    "   - F1 Score: 0.948756\n",
    "   \n",
    "   * The default Decision Tree model exhibits the highest accuracy and performance metrics among all the models.\n",
    "\n",
    "Finally, by observation, I can say that Decision Tree models, especially the default one, performed the best on the used car acceptability data. Among the ensemble models, the Random Forest models also showed strong performance, while AdaBoost falls behind in terms of accuracy and metrics. Gradient Boosting achieved the highest accuracy, precision, recall, and F1 score among all the models."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Class08b-decision_tree_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
